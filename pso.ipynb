{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step PSO Tutorial\n",
    "\n",
    "Below you find a step by step tutorial of a simplified, yet more performant variant of the PSO algorithm. \n",
    "Asside from numpy no external dependency is needed. Make sure to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to evaluate a function, we need to define it before starting. I choose the Rastrigin function, which is a little more complex than x^2 but not too complicated. It can be replaced by any number of functions applicable to arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(row: np.ndarray):\n",
    "    \"\"\"\n",
    "        apply rastrigin-function to matrix-row\n",
    "\n",
    "    :param row:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f_arr = np.frompyfunc(lambda d: d ** 2 - 10 * np.cos(np.pi * d) + 10, 1, 1)\n",
    "    return np.sum(f_arr(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set some constants. n depends on the function, the variable dims sets the dimensionality. \n",
    "Values c1 & c2 determined empirically (not by me) and are needed for the PSO algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5.2\n",
    "dims = 3\n",
    "func = rastrigin\n",
    "\n",
    "c1 = c2 = 1.494\n",
    "\n",
    "num_particles = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the positions of the particles and their velocities. Together they represent our swarm and it's movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.rand(num_particles, dims) * n +1\n",
    "x = 2 * n * np.random.rand(num_particles, dims) - n\n",
    "assert v.shape == x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to save the current best solutions of the particles as well as the global best solution. They will influence the positions or rather the velocities of the particles in our swarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solution = np.full((1, num_particles), sys.maxsize)\n",
    "best_point = np.zeros_like(x)\n",
    "best_global_point = np.zeros(dims)\n",
    "best_global_solution = sys.maxsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to the good stuff. Since we defined a very nice function above, which makes it possible to apply a function to a row, we can apply it to all rows/ particles at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = np.apply_along_axis(func, axis=1, arr=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we determine the best solutions of all particles. If the current solution is not better than the best solution of a given particle, it is - of course - not changed at all. The index is also used to get the position of the best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = fx < best_solution\n",
    "best_solution[idx] = fx[idx[0]]\n",
    "best_point[idx[0]] = x[idx[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, we want to update the global best solution and points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update global best solutions\n",
    "idx = np.argmin(best_solution)\n",
    "if best_solution[:, idx][0] < best_global_solution:\n",
    "    best_global_solution = best_solution[:,idx][0]\n",
    "    best_global_point = x[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the best solutions, we can update the velocities of the particles respective to the positions of their best solutions:\n",
    "$$v = v + rand * c_1 * (best\\_point -x)$$\n",
    "The same is done with respect to position of the global best solution:\n",
    "$$v = v + rand * c_2 * (global\\_best\\_point -x)$$\n",
    "\n",
    "This will drag the particles into the area of the current best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.ranf(2)\n",
    "v += r[0] * c1 * (best_point - x)\n",
    "v += c2 * r[1] * (best_global_point - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the particles is done by adding the velocites to the positions. In this implementation we don't want the particles to escape the search space, i.e. $-n, n$, thus we use np.clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "x += v\n",
    "x = np.clip(x, a_min=-n, a_max=n)\n",
    "print(f\"{best_global_solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.random.ranf(dims)\n",
    "# update highest velocity\n",
    "if np.sum(np.abs(particle.v)) < np.sum(np.abs(max_vel[,])):\n",
    "    max_vel = particle.v\n",
    "    \n",
    "# weird\n",
    "if np.sum(r1) < np.sum(particle.v):\n",
    "    v = r1 * v * max_vel ** rand_speed_factor\n",
    "    # select random dimension\n",
    "    ri = np.random.randint(dims)\n",
    "    # constant factor to keep the chaos realistic\n",
    "    x[ri] = r1[0] * ((2 * n) - n) * self.ws[i] * 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barely anthing happend? That's normal. The PSO algorithm is run iteratively, so lets add a for-loop an decreasing weights to decrease the influence of personal best solutions towards the end of the execution and wrap into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pso(num_particles, dims, iterations):\n",
    "\n",
    "\n",
    "    n = 5.2\n",
    "    func = rastrigin\n",
    "    c1 = c2 = 1.494    \n",
    "    \n",
    "    v = np.random.rand(num_particles, dims) * n +1\n",
    "    x = 2 * n * np.random.rand(num_particles, dims) - n\n",
    "    assert v.shape == x.shape\n",
    "\n",
    "    best_solution = np.full((1, num_particles), sys.maxsize)\n",
    "    best_point = np.zeros_like(x)\n",
    "    best_global_point = np.zeros(dims)\n",
    "    best_global_solution = sys.maxsize\n",
    "    ws = np.linspace(0.9, 0.4, iterations)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # apply function to all particles\n",
    "        fx = np.apply_along_axis(func, axis=1, arr=x)\n",
    "\n",
    "        # update best solutions of points\n",
    "        idx = fx < best_solution\n",
    "        best_solution[idx] = fx[idx[0]]\n",
    "        best_point[idx[0]] = x[idx[0], :]\n",
    "\n",
    "        # update global best solutions\n",
    "        idx = np.argmin(best_solution)\n",
    "        if best_solution[:,idx][0] < best_global_solution:\n",
    "            best_global_solution = best_solution[:,idx][0]\n",
    "            best_global_point = x[idx, :]\n",
    "\n",
    "        # update velocity after formula given constants c1 & c2, some randomness,\n",
    "        # and personal/ global best solutions.\n",
    "        r = np.random.ranf(2)\n",
    "        v = ws[i]*v + r[0] * c1 * (best_point - x)\n",
    "        # you can start the global updating later, if you want.\n",
    "        v += c2 * r[1] * (best_global_point - x)\n",
    "\n",
    "        # update position\n",
    "        x += v\n",
    "\n",
    "        # keep all particles in range [-n, n]\n",
    "        x = np.clip(x, a_min=-n, a_max=n)\n",
    "\n",
    "        print(f\"{best_global_solution}\")\n",
    "\n",
    "num_particles = 30\n",
    "dims = 10\n",
    "iterations = 100\n",
    "\n",
    "#run_pso(num_particles, dims, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "The Algorithm can be adjusted by adding even more chaos for both position and velocity. Let's first look at position, since it's easier to grasp. We first select a random dimension (you could also select multiple dimensions) and some particles, which we want to update. For this I chose 10% of the particles, which is arbitrary. After, the points are reset with a constant factor 0.45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5.\n",
    "r_dim = np.random.randint(dims)\n",
    "r_particles = np.random.choice(range(num_particles), num_particles//10)\n",
    "x[r_particles, r_dim] = np.random.ranf() * ((2 * n) - n) * 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets add some randomness to the velocities of the particles. We will need to keep track of the highest velocity and set a minimum velocity. I also added some code to add values once the particles move too slow. Notice that the particles a completely new velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_speed = 0.1\n",
    "# don't fall asleep.\n",
    "max_velocity = np.zeros(dims)\n",
    "p_vel_abs = np.sum(np.abs(v), axis=1)\n",
    "# update all particles, which have a speed which is below our threshold\n",
    "v[p_vel_abs < lowest_speed, :] += np.random.ranf(dims)\n",
    "\n",
    "# largest absolute velocity sum larger than max_vel\n",
    "max_vel_sum = np.sum(np.abs(max_velocity))\n",
    "# check if any particle is moving faster \n",
    "if np.any(max_vel_sum > p_vel_abs):\n",
    "    # get index of particle with highest velocity\n",
    "    _idx = np.argmax(np.sum((v[ max_vel_sum < p_vel_abs , :]), axis=1))\n",
    "    # update max_velocity\n",
    "    max_velocity = v[_idx, :]\n",
    "    \n",
    "# choose a random particle and update\n",
    "r_particles = np.random.choice(range(num_particles), num_particles // 10)\n",
    "# new velocities for selected particles\n",
    "vals = np.random.ranf((len(r_particles), dims)) * max_velocity\n",
    "v[r_particles, :] = vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code could be inserted directly into the main function. I chose to put into an inner function which let's me keep the code structure without moving everything into a class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
